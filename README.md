# UniLLM-TS

> ç»Ÿä¸€çš„ TypeScript LLM è°ƒç”¨åº“ï¼Œæ”¯æŒå¤šä¸ªä¸»æµå¤§è¯­è¨€æ¨¡å‹æä¾›å•†

[![npm version](https://img.shields.io/npm/v/unillm-ts.svg)](https://www.npmjs.com/package/unillm-ts)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue.svg)](https://www.typescriptlang.org/)

## ç‰¹æ€§

- ğŸš€ **è½»é‡çº§**ï¼šæ—  UIï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡
- ğŸ”„ **ç»Ÿä¸€æ¥å£**ï¼šæä¾›ä¸€è‡´çš„å¯¹è¯è°ƒç”¨æ–¹å¼
- ğŸ”Œ **å¯æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬å¯¹è¯ï¼Œåç»­å¯æ‰©å±•å…¶ä»–æ•°æ®æ ¼å¼
- ğŸ”’ **å®‰å…¨å­˜å‚¨**ï¼šæ”¯æŒåŠ å¯†å­˜å‚¨ API Keyï¼ˆä½¿ç”¨ keytarï¼‰
- ğŸ“¦ **æ˜“é›†æˆ**ï¼šä½œä¸º npm åŒ…ï¼Œä¸€è¡Œä»£ç å¼•å…¥
- âš™ï¸ **é…ç½®ç®¡ç†**ï¼šé€šè¿‡æ¨¡æ¿ä¸å®ä¾‹ç®¡ç† API Keyã€æ¨¡å‹ã€è¶…å‚ç­‰

## ç›®å‰è®¡åˆ’æ”¯æŒçš„æä¾›å•†

- [ ] OpenAI (GPT-4, GPT-3.5, etc.)
- [ ] Googleï¼ˆGeminiï¼‰
- [ ] é˜¿é‡Œäº‘é€šä¹‰åƒé—® (Qwen)
- [ ] æ™ºè°± AI (GLM-4)
- [ ] Moonshot AI (Kimi)
- [ ] è®¯é£æ˜Ÿç« (éœ€è¦ WebSocket å®ç°)

## Roadmap
- [ ] å®Œå–„æ¶æ„è®¾è®¡ï¼Œæä¾›å®Œå–„çš„ç®¡ç†ã€è®¿é—®æ¥å£
- [ ] ä¿è¯è®¿é—®çš„ç¨³å®šæ€§ã€å®‰å…¨æ€§
- [ ] å®Œå–„å¯¹æä¾›æ–¹çš„æ¥å…¥
- [ ] æ”¯æŒæ›´å¤šæä¾›å•†ï¼ˆå¦‚ç™¾åº¦æ–‡å¿ƒä¸€è¨€ã€å¾®è½¯ Azure OpenAI ç­‰ï¼‰
- [ ] æ”¯æŒæ›´çµæ´»çš„APIé…ç½®ã€é€‰æ‹©å’Œè°ƒç”¨æ–¹å¼
- [ ] å¢åŠ æ›´å¤šç¤ºä¾‹å’Œæ–‡æ¡£
- [ ] æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ç­‰ï¼‰
- [ ] æ”¯æŒMCP

## å®‰è£…

```bash
npm install unillm-ts
```

## å¿«é€Ÿå¼€å§‹

### 1. é…ç½® API Keys

é¦–å…ˆï¼Œä½¿ç”¨å®‰å…¨å­˜å‚¨è®¾ç½®æ‚¨çš„ API Keysï¼š

```typescript
import { setSecret } from 'unillm-ts';

// å­˜å‚¨ API Keys
await setSecret('openai-default-api_key', 'your-openai-key');
await setSecret('qwen-default-api_key', 'your-qwen-key');
await setSecret('zhipu-default-api_key', 'your-zhipu-key');
// æ ¹æ®æ¨¡æ¿éœ€æ±‚ï¼Œéƒ¨åˆ†æä¾›å•†è¿˜éœ€è¦é¢å¤–å­—æ®µï¼Œä¾‹å¦‚ï¼š
// await setSecret('qwen-default-access_key_id', 'your-aliyun-ak');
// await setSecret('qwen-default-access_key_secret', 'your-aliyun-sk');
```

### 2. æŸ¥çœ‹æ¨¡æ¿ä¸å®ä¾‹

UniLLM-TS å†…ç½®æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ã€é…ç½®æ¨¡æ¿ä»¥åŠåŸºäºæ¨¡æ¿ç”Ÿæˆçš„é»˜è®¤å®ä¾‹ã€‚åˆå§‹åŒ–åå¯ä»¥æŸ¥çœ‹å¹¶ç®¡ç†è¿™äº›å®ä¾‹ï¼š

```typescript
import llmManager from 'unillm-ts';

await llmManager.init();

const templates = llmManager.getConfigTemplates();
const instances = llmManager.listInstances();

console.log('Templates:', templates.map(t => ({ id: t.id, models: t.modelIds })));
console.log('Instances:', instances.map(inst => ({
  id: inst.id,
  template: inst.templateId,
  secretKeys: inst.secretKeys,
})));
```

æ¯ä¸ªå®ä¾‹éƒ½ä¼šç»™å‡ºéœ€è¦é…ç½®çš„ `secretKeys`ï¼ˆä¾‹å¦‚ `qwen-default-api_key`ï¼‰ã€‚ä½¿ç”¨ `setSecret` å†™å…¥çœŸå®å€¼åå³å¯è°ƒç”¨å¯¹åº”æä¾›æ–¹ã€‚

### 3. ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼ˆæ¨èï¼‰

```typescript
import llmManager from 'unillm-ts';

// åˆå§‹åŒ–
await llmManager.init();

// é€‰æ‹©å®ä¾‹ä¸æ¨¡å‹
const instances = llmManager.listInstances();
const current = instances.find(inst => inst.templateId === 'qwen') ?? instances[0];
if (!current) {
  throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„é…ç½®å®ä¾‹');
}
await llmManager.setCurrentInstance(current.id);
await llmManager.setCurrentModel('qwen-plus');

// æŸ¥è¯¢æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
const models = llmManager.listModels();
console.log('Available models:', models);

// ç®€å•å¯¹è¯ï¼ˆéæµå¼ï¼‰
const response = await llmManager.chatSimple('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±');
console.log(response);

// æµå¼å¯¹è¯
const stream = await llmManager.chatStream('å†™ä¸€é¦–è¯—');
for await (const chunk of stream) {
  process.stdout.write(chunk);
}
```

### 4. ä½¿ç”¨ç±»å®ä¾‹

```typescript
import { LLMManager } from 'unillm-ts';

const manager = new LLMManager();
await manager.init();

const instances = manager.listInstances();
const openaiInstance = instances.find(inst => inst.templateId === 'openai');
if (!openaiInstance) {
  throw new Error('æœªæ‰¾åˆ° OpenAI é…ç½®å®ä¾‹');
}
await manager.setCurrentInstance(openaiInstance.id);
await manager.setCurrentModel('gpt-4o');

// é«˜çº§å¯¹è¯æ¥å£
const response = await manager.chat({
  messages: [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹' },
    { role: 'user', content: 'è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™æ®µä»£ç ' }
  ],
  temperature: 0.7,
  max_tokens: 1000,
  stream: false
});

if (!('content' in response)) {
  throw new Error('Unexpected stream response');
}

console.log(response.content);
console.log('Usage:', response.usage);
```

## API æ–‡æ¡£

### LLMManager

#### `init(): Promise<void>`

åˆå§‹åŒ–ç®¡ç†å™¨ï¼ŒåŠ è½½å†…ç½®æ¨¡å‹ä¸æ¨¡æ¿ï¼Œå¹¶ä»æœ¬åœ° JSON ä¸­è¯»å–é…ç½®å®ä¾‹ã€‚

#### æ¨¡å‹ä¿¡æ¯
- `listModels(): string[]`
- `getModelsInfo(): ModelInfo[]`
- `getSupportedModels(): SupportedModel[]`
- `getCurrentInstanceModels(): SupportedModel[]`

```typescript
interface ModelInfo {
  id: string;
  name: string;
  provider: string;
  model: string;
  description?: string;
  parameters: Record<string, any>;
  dataFormats: {
    input: string[];
    output: string[];
  };
}
```

#### æ¨¡æ¿ä¸å®ä¾‹ç®¡ç†
- `getConfigTemplates(): ConfigTemplate[]`
- `createInstanceFromTemplate(templateId: string, options?: InstanceCreationOptions): Promise<ConfigInstanceSummary>`
- `listInstances(): ConfigInstanceSummary[]`
- `getInstance(instanceId: string): ConfigInstanceSummary | null`
- `updateInstance(instanceId: string, payload: InstanceUpdatePayload): Promise<ConfigInstanceSummary>`
- `setCurrentInstance(instanceId: string): Promise<void>`
- `getCurrentInstance(): ConfigInstanceSummary | null`
- `setCurrentModel(modelId: string): Promise<void>`
- `getCurrentModel(): string | null`
- `getModelConfig(modelId: string, instanceId?: string): Partial<ModelConfig> | null`

#### å¯¹è¯æ¥å£
- `chat(options: ChatCompletionOptions, selector?: string | { instanceId?: string; modelId?: string }): Promise<ChatCompletionResponse | AsyncGenerator<string>>`
- `chatSimple(message: string, selector?: string | { instanceId?: string; modelId?: string }): Promise<string>`
- `chatStream(message: string, selector?: string | { instanceId?: string; modelId?: string }): AsyncGenerator<string>`

#### å…¶ä»–
- `getSupportedProviders(): string[]`

### å®‰å…¨å­˜å‚¨

#### `setSecret(key: string, value: string): Promise<void>`

å­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚ API Keyï¼‰ã€‚

#### `getSecret(key: string): Promise<string | null>`

è·å–å­˜å‚¨çš„æ•æ„Ÿä¿¡æ¯ã€‚

## é…ç½®æ•°æ®è¯´æ˜

- æ¨¡å‹ä¿¡æ¯ï¼šä¿å­˜åœ¨ `src/config/models.json`ï¼Œæä¾›æ¨¡å‹ IDã€å‚æ•°ã€æ•°æ®æ ¼å¼ç­‰æè¿°ã€‚
- æ¨¡æ¿ä¿¡æ¯ï¼šä¿å­˜åœ¨ `src/config/templates.json`ï¼Œå®šä¹‰æ¯ä¸ªæä¾›æ–¹çš„é»˜è®¤é…ç½®ä¸æ‰€éœ€å¯†é’¥ã€‚
- é…ç½®å®ä¾‹ï¼šè¿è¡Œæ—¶ä¿å­˜åœ¨ç”¨æˆ·ç›®å½• `~/.unillm/instances.json`ï¼Œæ¯ä¸ªå®ä¾‹åŒ…å«åç§°ã€é…ç½®è¦†ç›–é¡¹ä¸ `secretKeys`ã€‚
- å½“å‰çŠ¶æ€ï¼šå½“å‰å®ä¾‹ä¸æ¨¡å‹ä¿å­˜åœ¨ `~/.unillm/state.json`ï¼Œä¾¿äºä¸‹æ¬¡å¯åŠ¨æ—¶æ¢å¤ã€‚

> æç¤ºï¼šæ¨¡æ¿ä»…ç”±å¼€å‘è€…æä¾›ï¼Œæ„å»ºåæ— æ³•é€šè¿‡è¿è¡Œæ—¶ä¿®æ”¹æ¨¡æ¿æ–‡ä»¶ã€‚è‹¥éœ€è¦æ–°å¢æˆ–è°ƒæ•´æ¨¡æ¿ï¼Œè¯·åœ¨å‘å¸ƒå‰æ›´æ–°å¯¹åº” JSONã€‚

## æ‰©å±•æ€§

åº“è®¾è®¡ä¸ºå¯æ‰©å±•çš„ï¼Œæ”¯æŒï¼š

1. **æ·»åŠ æ–°çš„æä¾›å•†**ï¼šå®ç° `LLMProvider` æŠ½è±¡ç±»
2. **å¤šæ¨¡æ€è¾“å…¥**ï¼š`MessageContent` æ¥å£æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€æ–‡ä»¶ç­‰ç±»å‹
3. **è‡ªå®šä¹‰é…ç½®**ï¼šé…ç½®é¡¹æ”¯æŒä»»æ„æ‰©å±•å­—æ®µ

### æ·»åŠ æ–°æä¾›å•†ç¤ºä¾‹

```typescript
import { LLMProvider } from 'unillm-ts';
import { ChatCompletionOptions, ChatCompletionResponse } from 'unillm-ts';

export class MyCustomProvider extends LLMProvider {
  async chatCompletion(
    options: ChatCompletionOptions
  ): Promise<ChatCompletionResponse | AsyncGenerator<string>> {
    // å®ç°æ‚¨çš„æä¾›å•†é€»è¾‘
  }
}
```

## æ³¨æ„äº‹é¡¹

1. **keytar ä¾èµ–**ï¼šéœ€è¦ç³»ç»Ÿæ”¯æŒ keytarï¼ˆå¯èƒ½éœ€è¦é¢å¤–çš„ç³»ç»Ÿåº“ï¼‰
2. **è®¯é£æ˜Ÿç«**ï¼šç›®å‰éœ€è¦ WebSocket å®ç°ï¼Œè¯·å‚è€ƒå®˜æ–¹ SDK
3. **API å¯†é’¥å®‰å…¨**ï¼šå»ºè®®ä½¿ç”¨ `@secret:` å‰ç¼€å­˜å‚¨æ•æ„Ÿä¿¡æ¯

## å¼€å‘

```bash
# å®‰è£…ä¾èµ–
npm install

# æ„å»º
npm run build

# å¼€å‘æ¨¡å¼ï¼ˆwatchï¼‰
npm run dev
```

## è®¸å¯è¯

MIT

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

